{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2170465,"sourceType":"datasetVersion","datasetId":1165452}],"dockerImageVersionId":30786,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Kütüphaneleri Çağırmak\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\n\nimport struct\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport tensorflow as tf","metadata":{"execution":{"iopub.status.busy":"2024-10-18T06:24:36.815713Z","iopub.execute_input":"2024-10-18T06:24:36.816217Z","iopub.status.idle":"2024-10-18T06:24:55.583444Z","shell.execute_reply.started":"2024-10-18T06:24:36.816162Z","shell.execute_reply":"2024-10-18T06:24:55.582134Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## GPU Üzerinden Eğitim Yapmak","metadata":{}},{"cell_type":"code","source":"tf.config.list_physical_devices(\"GPU\")","metadata":{"execution":{"iopub.status.busy":"2024-10-18T06:24:55.584822Z","iopub.execute_input":"2024-10-18T06:24:55.585557Z","iopub.status.idle":"2024-10-18T06:24:55.596956Z","shell.execute_reply.started":"2024-10-18T06:24:55.585508Z","shell.execute_reply":"2024-10-18T06:24:55.595544Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Verileri  İncelemek → .png","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\n\nimport os \nfor dirname ,_, filenames in os.walk(\"/kaggle/input/a-large-scale-fish-dataset/Fish_Dataset\"):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"execution":{"iopub.status.busy":"2024-10-18T06:24:55.598826Z","iopub.execute_input":"2024-10-18T06:24:55.599605Z","iopub.status.idle":"2024-10-18T06:25:00.108731Z","shell.execute_reply.started":"2024-10-18T06:24:55.599539Z","shell.execute_reply":"2024-10-18T06:25:00.107396Z"},"trusted":true,"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Toplam Veri Sayısına Erişmek → 18000","metadata":{}},{"cell_type":"code","source":"import os\nfrom sklearn.model_selection import train_test_split\n\n# Veri setindeki tüm dosya yollarını listelemek\nimage_dir = \"/kaggle/input/a-large-scale-fish-dataset/Fish_Dataset/Fish_Dataset/\"\nimage_paths = []\n\nfor dirname, _, filenames in os.walk(image_dir):\n    for filename in filenames:\n        if filename.endswith(('.png', '.jpg', '.jpeg')):  # Sadece görüntü dosyalarını seçmek\n            image_paths.append(os.path.join(dirname, filename))\n\nprint(f\"Toplam {len(image_paths)} görüntü bulundu.\")\n\n# Tüm görüntülerin sınıflarını elde etmek\nlabels = [os.path.basename(os.path.dirname(path)) for path in image_paths]\n\n# Sınıf dağılımını görmek için\nlabel_counts = pd.Series(labels).value_counts()\n\nprint(\"Sınıf Dağılımı:\")\nprint(label_counts)\n\n# Tüm sınıflar için veriler eşit dağılıyor.\n","metadata":{"execution":{"iopub.status.busy":"2024-10-18T06:25:00.111555Z","iopub.execute_input":"2024-10-18T06:25:00.111986Z","iopub.status.idle":"2024-10-18T06:25:00.281191Z","shell.execute_reply.started":"2024-10-18T06:25:00.111942Z","shell.execute_reply":"2024-10-18T06:25:00.279892Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Veri Setlerini Taşımak","metadata":{}},{"cell_type":"code","source":"import os\nimport shutil\n\n# Orijinal veri seti dizini\nbase_dir = '/kaggle/input/a-large-scale-fish-dataset/Fish_Dataset/Fish_Dataset'\n# Yeni dizin yapısı\nnew_base_dir = '/kaggle/working'\n\n# Dizin içeriğini kontrol et\nprint(\"Dizin içeriği:\")\nfor root, dirs, files in os.walk(base_dir):\n    if not dirs:  # Sadece dosyaları içeren dizinleri al\n        if files:\n            class_name = os.path.basename(root)  # Dizin ismini al\n            class_new_dir = os.path.join(new_base_dir, class_name)\n            os.makedirs(class_new_dir, exist_ok=True)  # Yeni dizin oluştur\n            for img in files:\n                if img.endswith(('.png', '.jpg')):  # Görüntü uzantıları\n                    src = os.path.join(root, img)\n                    dst = os.path.join(class_new_dir, img)\n                    shutil.copy(src, dst)  # Görüntüyü kopyala\n                    # print(f\"{src} taşındı.\")  # Eğer görmek istersek taşınıp taşınmadığını yorum satırından kaldırabiliriz.\n    \nprint(\"Görüntüler başarıyla taşındı.\")\n\n# Toplam görüntü sayısını yazdır\ndef count_images(directory):\n    total_count = 0\n    for root, dirs, files in os.walk(directory):\n        total_count += len([img for img in files if img.endswith(('.png', '.jpg'))]) #görüntü formatları\n    return total_count\n\ntotal_images = count_images(new_base_dir)\nprint(f\"Yeni dizinde toplam {total_images} görüntü var.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-18T06:25:00.282838Z","iopub.execute_input":"2024-10-18T06:25:00.283289Z","iopub.status.idle":"2024-10-18T06:27:23.025530Z","shell.execute_reply.started":"2024-10-18T06:25:00.283226Z","shell.execute_reply":"2024-10-18T06:27:23.023991Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Veri Setini Bölmek →  (%70 Train, %20 Val, %10 Test)","metadata":{}},{"cell_type":"code","source":"\nimport os\nimport shutil\nimport random\n\n# Mevcut veri seti dizini\nbase_dir = '/kaggle/working'\n\n# Yeni dizinler (train, val, test)\ntrain_dir = '/kaggle/working/train'\nval_dir = '/kaggle/working/val'\ntest_dir = '/kaggle/working/test'\n\n# Bu dizinleri oluştur\nos.makedirs(train_dir, exist_ok=True)\nos.makedirs(val_dir, exist_ok=True)\nos.makedirs(test_dir, exist_ok=True)\n\n# Veri setini bölme oranları\ntrain_split = 0.7\nval_split = 0.2\ntest_split = 0.1\n\n# Her sınıfı dolaşıp, görüntüleri ayırma işlemi\nfor class_name in os.listdir(base_dir):\n    class_path = os.path.join(base_dir, class_name)\n    \n    if os.path.isdir(class_path) and class_name not in ['train', 'val', 'test']:  # Sadece sınıf klasörlerini kontrol et\n        # Sınıf için görüntü dosyalarını al\n        images = [img for img in os.listdir(class_path) if img.endswith(('.png', '.jpg'))]\n        \n        # Görüntüleri karıştır (shuffle)\n        random.shuffle(images)\n        \n        # Her sınıf için train, val, test setleri için sınırları belirle\n        total_images = len(images)\n        train_count = int(total_images * train_split)\n        val_count = int(total_images * val_split)\n        \n        # Görüntüleri ayır\n        train_images = images[:train_count]\n        val_images = images[train_count:train_count + val_count]\n        test_images = images[train_count + val_count:]\n        \n        # Her set için hedef klasörü oluştur\n        train_class_dir = os.path.join(train_dir, class_name)\n        val_class_dir = os.path.join(val_dir, class_name)\n        test_class_dir = os.path.join(test_dir, class_name)\n        \n        os.makedirs(train_class_dir, exist_ok=True)\n        os.makedirs(val_class_dir, exist_ok=True)\n        os.makedirs(test_class_dir, exist_ok=True)\n        \n        # Train görüntülerini taşı\n        for img in train_images:\n            src = os.path.join(class_path, img)\n            dst = os.path.join(train_class_dir, img)\n            shutil.move(src, dst)\n        \n        # Val görüntülerini taşı\n        for img in val_images:\n            src = os.path.join(class_path, img)\n            dst = os.path.join(val_class_dir, img)\n            shutil.move(src, dst)\n        \n        # Test görüntülerini taşı\n        for img in test_images:\n            src = os.path.join(class_path, img)\n            dst = os.path.join(test_class_dir, img)\n            shutil.move(src, dst)\n\n        # Sınıf dizinini sil\n        shutil.rmtree(class_path)\n\nprint(\"Görüntüler başarıyla train, val ve test setlerine bölündü, diğer dosyalar silindi.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-18T06:27:45.212097Z","iopub.execute_input":"2024-10-18T06:27:45.212729Z","iopub.status.idle":"2024-10-18T06:27:45.234843Z","shell.execute_reply.started":"2024-10-18T06:27:45.212677Z","shell.execute_reply":"2024-10-18T06:27:45.233227Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Taşınan Verilerin Dizindeki Sayısı","metadata":{}},{"cell_type":"code","source":"import os\n\n# Dizinlerdeki görüntü sayısını hesaplayan fonksiyon\ndef count_images(directory):\n    total_count = 0\n    for root, dirs, files in os.walk(directory):\n        total_count += len([img for img in files if img.endswith(('.png', '.jpg'))]) # Görüntü formatları\n    return total_count\n\n# Train, Val, Test dizinlerinin yolu\ntrain_dir = '/kaggle/working/train'\nval_dir = '/kaggle/working/val'\ntest_dir = '/kaggle/working/test'\n\n# Her bir dizindeki toplam görüntü sayısını yazdır\ntrain_count = count_images(train_dir)\nval_count = count_images(val_dir)\ntest_count = count_images(test_dir)\n\nprint(f\"Train dizininde toplam {train_count} görüntü var.\")\nprint(f\"Val dizininde toplam {val_count} görüntü var.\")\nprint(f\"Test dizininde toplam {test_count} görüntü var.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-18T06:27:56.773778Z","iopub.execute_input":"2024-10-18T06:27:56.774794Z","iopub.status.idle":"2024-10-18T06:27:56.817376Z","shell.execute_reply.started":"2024-10-18T06:27:56.774739Z","shell.execute_reply":"2024-10-18T06:27:56.815817Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Verileri Çoğaltmak Ve Görselleştirmek","metadata":{}},{"cell_type":"markdown","source":"* Bu işlemi overfitting'i önlemek için yaptım: Overfitting → Modelin verileri genelleyerek aşırı öğrenmesine sebep olur bu yüzden accuracy değerimiz yüksek görünürken predict işleminde yeteri kadar iyi sonuç elde edilmez.","metadata":{}},{"cell_type":"markdown","source":"* Bu işlem biraz fazla sürebilir çünkü train,test,val içerisindeki sınıfların her birinin içindeki görüntüleri sağa ve sola çevirerek aynı dizin içerisinde çoğaltıyoruz.(Yaklaşık 45 Dakika Sürdü)","metadata":{}},{"cell_type":"code","source":"import os\nimport random\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\n# Görüntü çoğaltma fonksiyonu (sağa ve sola döndürme)\ndef augment_and_save_image(image_path, save_dir):\n    image = Image.open(image_path)\n    \n    # Orijinal görüntüyü kaydetme (kopyalamaya gerek yok, zaten mevcut)\n    original_image = image.copy()\n\n    # Görüntüyü sağa döndür (90 derece)\n    rotated_right = image.rotate(-90)\n    right_save_path = os.path.join(save_dir, os.path.splitext(os.path.basename(image_path))[0] + \"_rotated_right.png\")\n    rotated_right.save(right_save_path)\n\n    # Görüntüyü sola döndür (90 derece)\n    rotated_left = image.rotate(90)\n    left_save_path = os.path.join(save_dir, os.path.splitext(os.path.basename(image_path))[0] + \"_rotated_left.png\")\n    rotated_left.save(left_save_path)\n\n    return original_image, rotated_right, rotated_left\n\n# Görüntü çoğaltmayı her dizin için uygula\ndef augment_images_in_directory(base_dir):\n    for root, dirs, files in os.walk(base_dir):\n        for file in files:\n            if file.endswith(('.png', '.jpg')):\n                image_path = os.path.join(root, file)\n                augment_and_save_image(image_path, root)\n\n# Örnek görselleri göstermek için\ndef display_augmented_images(base_dir, num_samples=5):\n    # Rastgele 5 görüntü seç\n    image_paths = []\n    for root, dirs, files in os.walk(base_dir):\n        for file in files:\n            if file.endswith(('.png', '.jpg')):\n                image_paths.append(os.path.join(root, file))\n    \n    random_images = random.sample(image_paths, num_samples)\n    \n    # Orijinal ve döndürülmüş görüntüleri göster\n    for img_path in random_images:\n        original_image, rotated_right, rotated_left = augment_and_save_image(img_path, os.path.dirname(img_path))\n        \n        plt.figure(figsize=(10, 5))\n        \n        # Orijinal görüntü\n        plt.subplot(1, 3, 1)\n        plt.imshow(original_image)\n        plt.title(\"Original\")\n        plt.axis('off')\n\n        # Sağa döndürülmüş görüntü\n        plt.subplot(1, 3, 2)\n        plt.imshow(rotated_right)\n        plt.title(\"Rotated Right\")\n        plt.axis('off')\n\n        # Sola döndürülmüş görüntü\n        plt.subplot(1, 3, 3)\n        plt.imshow(rotated_left)\n        plt.title(\"Rotated Left\")\n        plt.axis('off')\n        \n        plt.show()\n\n# Train, Val ve Test dizinlerine uygulama\ntrain_dir = '/kaggle/working/train'\nval_dir = '/kaggle/working/val'\ntest_dir = '/kaggle/working/test'\n\n# Her dizindeki görüntüleri çoğalt\naugment_images_in_directory(train_dir)\naugment_images_in_directory(val_dir)\naugment_images_in_directory(test_dir)\n\n# Örnek görüntüleri görselleştirme (rastgele 5 görüntü)\ndisplay_augmented_images(train_dir, num_samples=5)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-18T06:30:23.947368Z","iopub.execute_input":"2024-10-18T06:30:23.947824Z","iopub.status.idle":"2024-10-18T07:07:59.954557Z","shell.execute_reply.started":"2024-10-18T06:30:23.947783Z","shell.execute_reply":"2024-10-18T07:07:59.953017Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Çoğaltılan Verilerle Birlikte Veri Sayısı → 54000","metadata":{}},{"cell_type":"markdown","source":"* Train görüntüsü sayısı: 12600\n* Validation görüntüsü sayısı: 3600\n* Test görüntüsü sayısı: 1800\n* Çoğaltılmadan Önceki Verilerin sayısı buydu: 18000","metadata":{}},{"cell_type":"markdown","source":"* Yeni Train görüntüsü sayısı: 41484\n* Yeni Validation görüntüsü sayısı: 10800\n* Yeni Test görüntüsü sayısı: 5400\n* Çoğaltılan verilerle birlikte toplam veri sayısı: Yaklaşık 58000","metadata":{}},{"cell_type":"code","source":"import os\n\n# Dizinlerdeki görüntü sayısını hesaplayan fonksiyon\ndef count_images(directory):\n    total_count = 0\n    for root, dirs, files in os.walk(directory):\n        total_count += len([img for img in files if img.endswith(('.png', '.jpg'))]) # Görüntü formatları\n    return total_count\n# jpg yazmamın nedeni kontrol amaçlı\n\n# Train, Val, Test dizinlerinin yolu\ntrain_dir = '/kaggle/working/train'\nval_dir = '/kaggle/working/val'\ntest_dir = '/kaggle/working/test'\n\n# Her bir dizindeki toplam görüntü sayısını yazdır\ntrain_count = count_images(train_dir)\nval_count = count_images(val_dir)\ntest_count = count_images(test_dir)\n\nprint(f\"Train dizininde toplam {train_count} görüntü var.\")\nprint(f\"Val dizininde toplam {val_count} görüntü var.\")\nprint(f\"Test dizininde toplam {test_count} görüntü var.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-18T07:07:59.957081Z","iopub.execute_input":"2024-10-18T07:07:59.958165Z","iopub.status.idle":"2024-10-18T07:08:00.073676Z","shell.execute_reply.started":"2024-10-18T07:07:59.958103Z","shell.execute_reply":"2024-10-18T07:08:00.072378Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Dizinleri Tanımlamak","metadata":{}},{"cell_type":"markdown","source":"* Öncelikle veri dizinlerimizi tanımlıyoruz. Veriler, train, val (validation) ve test dizinlerinde yer alıyor:","metadata":{}},{"cell_type":"code","source":"train_dir = '/kaggle/working/train'\nval_dir = '/kaggle/working/val'\ntest_dir = '/kaggle/working/test'","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Görüntü Boyutu ve Batch Size Ayarlarlamak","metadata":{}},{"cell_type":"markdown","source":"* Görüntülerin boyutunu 28x28 olarak seçtik ve her batch'te 32 görüntü işlemeyi planlıyoruz.","metadata":{}},{"cell_type":"code","source":"img_size = (28, 28)\nbatch_size = 32","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## ImageDataGenerator Kullanarak Veri Ön İşlemek","metadata":{}},{"cell_type":"markdown","source":"* Verilerimizi normalize etmek için ImageDataGenerator kullanıyoruz. Bu işlem, görüntülerin her bir piksel değerini 0 ile 1 arasında ölçekliyor (rescale=1./255). Her bir veri seti (train, val, test) için ayrı bir generator oluşturuyoruz.","metadata":{}},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(rescale=1./255)\nval_datagen = ImageDataGenerator(rescale=1./255)\ntest_datagen = ImageDataGenerator(rescale=1./255)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Verileri Yükleme","metadata":{}},{"cell_type":"markdown","source":"* flow_from_directory fonksiyonu ile verilerimizi yükleyerek, modelin öğrenmesi için uygun hale getiriyoruz. Verileri categorical (çok sınıflı) olarak işliyoruz","metadata":{}},{"cell_type":"code","source":"train_generator = train_datagen.flow_from_directory(train_dir, ...)\nval_generator = val_datagen.flow_from_directory(val_dir, ...)\ntest_generator = test_datagen.flow_from_directory(test_dir, ...)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Sınıf Sayısını Belirlemek","metadata":{}},{"cell_type":"markdown","source":"* Veri setimizdeki sınıfları belirlemek için train_generator.class_indices kullanarak sınıf sayısını alıyoruz. Bu, çıktı katmanında kullanacağımız sınıf sayısını belirlememize yardımcı oluyor.","metadata":{}},{"cell_type":"code","source":"num_classes = len(train_generator.class_indices)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## ANN Modelinin Oluşturulması","metadata":{}},{"cell_type":"markdown","source":"* Modelimizi Sequential yapı ile oluşturuyoruz. Aşağıdaki gibi tamamen bağlı (dense) katmanlar kullanıyoruz:\n\n* İlk olarak, giriş verisini düzleştiriyoruz (Flatten), çünkü ANN modelleri giriş olarak düzleştirilmiş (flat) veri alır.\n* Üç tane gizli katman ekleyerek 512, 256, 128 nöronlu katmanlar oluşturuyoruz.\n* Dropout ile overfitting'i önlemeye çalışıyoruz.\n* Çıkış katmanı olarak softmax aktivasyon fonksiyonu ile sınıf sayısı kadar nöron ekliyoruz.","metadata":{}},{"cell_type":"code","source":"model = tf.keras.models.Sequential()\nmodel.add(tf.keras.layers.Flatten(input_shape=(28, 28, 3)))\nmodel.add(tf.keras.layers.Dense(512, activation='relu'))\nmodel.add(tf.keras.layers.Dropout(0.3))\nmodel.add(tf.keras.layers.Dense(256, activation='relu'))\nmodel.add(tf.keras.layers.Dropout(0.3))\nmodel.add(tf.keras.layers.Dense(128, activation='relu'))\nmodel.add(tf.keras.layers.Dropout(0.3))\nmodel.add(tf.keras.layers.Dense(num_classes, activation='softmax'))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Modelin Derlenmesi","metadata":{}},{"cell_type":"markdown","source":"* Modeli derlerken Adam optimizer kullanıyoruz.\n  \n*  Çok sınıflı sınıflandırma için categorical_crossentropy loss fonksiyonunu ve accuracy metriğini seçiyoruz.","metadata":{}},{"cell_type":"code","source":"model.compile(optimizer='adam', \n              loss='categorical_crossentropy', \n              metrics=['accuracy'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Early Stopping Kullanmak","metadata":{}},{"cell_type":"markdown","source":"* Aşırı öğrenmeyi (overfitting) önlemek için early stopping kullanıyoruz. Eğer modelin doğrulama kaybı (val_loss) 5 epoch boyunca iyileşmezse eğitim duracak ve en iyi ağırlıklar geri yüklenecek.","metadata":{}},{"cell_type":"code","source":"early_stopping = tf.keras.callbacks.EarlyStopping(\n    monitor='val_loss',\n    patience=5,\n    restore_best_weights=True,\n    verbose=1\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Model Eğitimi","metadata":{}},{"cell_type":"markdown","source":"* Modeli 50 epoch boyunca eğitiyoruz, ancak early stopping devreye girerse daha erken durabilir. Eğitim sırasında doğrulama verisi ile modelin başarımını izliyoruz.","metadata":{}},{"cell_type":"code","source":"results = model.fit(\n    train_generator,\n    epochs=50,\n    validation_data=val_generator,\n    callbacks=[early_stopping]\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Performans Metrikleri Ve Tablo Oluşturulması","metadata":{}},{"cell_type":"code","source":"test_loss, test_acc = model.evaluate(test_generator)\nprint(f'Test loss: {test_loss}, Test accuracy: {test_acc}')\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Test seti üzerindeki performansı değerlendirme\ntest_loss, test_acc = model.evaluate(test_generator)\nprint(f'Test loss: {test_loss}, Test accuracy: {test_acc}')\n\n# Eğitim ve doğrulama kayıplarını çiz\nplt.plot(results.history['loss'], label='Eğitim Loss')\nplt.plot(results.history['val_loss'], label='Doğrulama Loss')\nplt.title('Eğitim ve Doğrulama Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()\n\n# Eğitim ve doğrulama doğruluğunu çiz\nplt.plot(results.history['accuracy'], label='Eğitim Accuracy')\nplt.plot(results.history['val_accuracy'], label='Doğrulama Accuracy')\nplt.title('Eğitim ve Doğrulama Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Tüm Eğitimi Tek Kodla Yapmak","metadata":{}},{"cell_type":"markdown","source":"* Ayrı kod bloklarında yaptığımda hatalarla karşılaştığımdan hepsini tek bir blokta yazarak birleştirdim.","metadata":{}},{"cell_type":"code","source":"import os\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport matplotlib.pyplot as plt\n\n\n# Eğitim ve doğrulama dizinleri\ntrain_dir = '/kaggle/working/train'\nval_dir = '/kaggle/working/val'\ntest_dir = '/kaggle/working/test'\n\n# Görüntülerin boyutu ve batch size\nimg_size = (28, 28)\nbatch_size = 32\n\n# Verileri ön işlemek için ImageDataGenerator\ntrain_datagen = ImageDataGenerator(rescale=1./255)\nval_datagen = ImageDataGenerator(rescale=1./255)\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\n# Eğitim verisini hazırlama\ntrain_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=img_size,\n    batch_size=batch_size,\n    class_mode='categorical'\n)\n\n# Doğrulama verisini hazırlama\nval_generator = val_datagen.flow_from_directory(\n    val_dir,\n    target_size=img_size,\n    batch_size=batch_size,\n    class_mode='categorical'\n)\n\n# Test verisini hazırlama\ntest_generator = test_datagen.flow_from_directory(\n    test_dir,\n    target_size=img_size,\n    batch_size=batch_size,\n    class_mode='categorical'\n)\n\n# Sınıf sayısını kontrol etme\nnum_classes = len(train_generator.class_indices)\nprint(f\"Sınıf Sayısı: {num_classes}\")\n\n# Modeli oluşturma (ANN - Yapay Sinir Ağı)\nmodel = tf.keras.models.Sequential()\n\n# Giriş katmanı: Görüntüleri düzleştiriyoruz (28x28 boyutunda giriş)\nmodel.add(tf.keras.layers.Flatten(input_shape=(28, 28, 3)))\n\n# Gizli katmanlar\nmodel.add(tf.keras.layers.Dense(512, activation='relu'))  # 1. Gizli katman\nmodel.add(tf.keras.layers.Dropout(0.3))  # Dropout ile overfitting'i önleme\n\nmodel.add(tf.keras.layers.Dense(256, activation='relu'))  # 2. Gizli katman\nmodel.add(tf.keras.layers.Dropout(0.3))\n\nmodel.add(tf.keras.layers.Dense(128, activation='relu'))  # 3. Gizli katman\nmodel.add(tf.keras.layers.Dropout(0.3))\n\n# Çıktı katmanı: Sınıf sayısına göre çıktı (softmax ile)\nmodel.add(tf.keras.layers.Dense(num_classes, activation='softmax'))\n\n# Modeli derleme\nmodel.compile(optimizer='adam', \n              loss='categorical_crossentropy', \n              metrics=['accuracy'])\n\n# Early stopping (aşırı öğrenmeyi önlemek için)\nearly_stopping = tf.keras.callbacks.EarlyStopping(\n    monitor='val_loss',  # İzlenecek metrik \n    patience=5,          # val_loss iyileşmezse 5 epoch sonra durdur\n    restore_best_weights=True,  # En iyi modelin ağırlıklarını geri yükle\n    verbose=1\n)\n\n# Modeli eğitme\nresults = model.fit(\n    train_generator,\n    epochs=100,  # 50 Epoch yeterli olabilir\n    validation_data=val_generator,\n    callbacks=[early_stopping]\n)\n\n# Test seti üzerindeki performansı değerlendirme\ntest_loss, test_acc = model.evaluate(test_generator)\nprint(f'Test loss: {test_loss}, Test accuracy: {test_acc}')\n\n# Eğitim ve doğrulama kayıplarını çiz\nplt.plot(results.history['loss'], label='Eğitim Loss')\nplt.plot(results.history['val_loss'], label='Doğrulama Loss')\nplt.title('Eğitim ve Doğrulama Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()\n\n# Eğitim ve doğrulama doğruluğunu çiz\nplt.plot(results.history['accuracy'], label='Eğitim Accuracy')\nplt.plot(results.history['val_accuracy'], label='Doğrulama Accuracy')\nplt.title('Eğitim ve Doğrulama Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-18T07:13:20.870752Z","iopub.execute_input":"2024-10-18T07:13:20.871322Z","iopub.status.idle":"2024-10-18T10:14:23.453414Z","shell.execute_reply.started":"2024-10-18T07:13:20.871243Z","shell.execute_reply":"2024-10-18T10:14:23.449942Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"* Model 33. epoch'ta early stopping ile durduruldu.","metadata":{}},{"cell_type":"markdown","source":"## Modelin h5 uzantısını kaydetmek","metadata":{}},{"cell_type":"code","source":"# Modeli belirli bir path'e kaydetme\nmodel.save('/kaggle/working/model.h5')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-18T10:15:11.798940Z","iopub.execute_input":"2024-10-18T10:15:11.799532Z","iopub.status.idle":"2024-10-18T10:15:11.905827Z","shell.execute_reply.started":"2024-10-18T10:15:11.799478Z","shell.execute_reply":"2024-10-18T10:15:11.904074Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Neden Bu Yapıları Seçtim?","metadata":{}},{"cell_type":"markdown","source":"* Dropout Katmanları: Overfitting'i önlemek için dropout ekledik.\n* Veri Çoğaltma: Daha önceden edindiğim data_augmentation tekniklerini kullanarak overfitting yani genelleme ve aşırı öğrenmeyi minimum seviyeye getirmek için veri setini 3 kat arttırmayı düşündüm buna bağlı olarak epoch sayısını da yüksek tutmak istedim.\n* Early Stopping: Eğitim süresince aşırı öğrenmenin önüne geçmek amacıyla early stopping kullandık.\n* Softmax Aktivasyonu: Multi-class sınıflandırma için çıkış katmanında softmax kullandık.","metadata":{}}]}